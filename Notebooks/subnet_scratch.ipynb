{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import math\n",
    "import hess\n",
    "import hess.utils as utils\n",
    "import matplotlib.pyplot as plt\n",
    "from hess.nets import Transformer\n",
    "import hess.loss_surfaces as loss_surfaces\n",
    "from hess.data import data_loader\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twospirals(n_points, noise=.5, random_state=920):\n",
    "    \"\"\"\n",
    "     Returns the two spirals dataset.\n",
    "    \"\"\"\n",
    "    n = np.sqrt(np.random.rand(n_points,1)) * 600 * (2*np.pi)/360\n",
    "    d1x = -1.5*np.cos(n)*n + np.random.randn(n_points,1) * noise\n",
    "    d1y =  1.5*np.sin(n)*n + np.random.randn(n_points,1) * noise\n",
    "    return (np.vstack((np.hstack((d1x,d1y)),np.hstack((-d1x,-d1y)))),\n",
    "            np.hstack((np.zeros(n_points),np.ones(n_points))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = twospirals(500, noise=1.3)\n",
    "test_x, test_y = twospirals(100, 1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.FloatTensor(X)\n",
    "train_y = torch.FloatTensor(Y).unsqueeze(-1)\n",
    "\n",
    "test_x = torch.FloatTensor(test_x)\n",
    "test_y = torch.FloatTensor(test_y).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimus = Transformer(train_x, train_y, net=hess.nets.MoonNet, n_hidden=3, hidden_size=10,\n",
    "                     activation=torch.nn.ELU(), bias=True)\n",
    "network = optimus.net\n",
    "loss_func = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda =  torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    torch.cuda.set_device(2)\n",
    "    train_x, train_y = train_x.cuda(), train_y.cuda()\n",
    "    test_x, test_y = test_x.cuda(), test_y.cuda()\n",
    "    network = network.cuda()\n",
    "    optimus = optimus.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_pars(p, mask):\n",
    "    p.data = p.data * mask\n",
    "    \n",
    "def mask_maker(n_keep, n_total, use_cuda=False):\n",
    "    mask = [1 for i in range(n_keep)] + [0 for i in range(n_total - n_keep)]\n",
    "    mask = torch.tensor(mask)\n",
    "    perm = np.random.permutation(n_total)\n",
    "    mask = mask[perm]\n",
    "    if use_cuda:\n",
    "        mask = mask.cuda()\n",
    "    return mask, perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-cf9dbe61d8b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mbase_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mbase_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         utils.eval_hess_vec_prod(base_vec, temp_net.parameters(),\n\u001b[1;32m     26\u001b[0m                                 \u001b[0mnet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemp_net\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/hess_truck/hess/utils.py\u001b[0m in \u001b[0;36munflatten_like\u001b[0;34m(vector, likeTensorList)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# print(tensor.numel())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# n = module._parameters[name].numel()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0moutList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_trial = 100\n",
    "pct_keep = .75\n",
    "n_par = sum(torch.numel(p) for p in network.parameters())\n",
    "n_keep = int(pct_keep * n_par)\n",
    "\n",
    "losses = torch.zeros(n_trial)\n",
    "test_losses = torch.zeros(n_trial)\n",
    "hessians = torch.zeros(n_trial, n_keep, n_keep)\n",
    "for tt in range(n_trial): \n",
    "    \n",
    "    ## set up the mask to generate a subnetwork ##\n",
    "    temp_net = copy.deepcopy(network)\n",
    "    mask, perm = mask_maker(n_keep, n_par, use_cuda)\n",
    "\n",
    "    mask = utils.unflatten_like(mask.unsqueeze(0), temp_net.parameters())\n",
    "    [mask_pars(p, mask[i]) for i, p in enumerate(temp_net.parameters())]\n",
    "    \n",
    "    ## compute the hessian of the masked network ##\n",
    "    sub_hess = torch.zeros(n_par, n_par)\n",
    "    for pp in range(n_par):\n",
    "        base_vec = torch.zeros(n_par).unsqueeze(0)\n",
    "        base_vec[0, pp] = 1.\n",
    "\n",
    "        base_vec = utils.unflatten_like(base_vec, temp_net.parameters())\n",
    "        utils.eval_hess_vec_prod(base_vec, temp_net.parameters(),\n",
    "                                net=temp_net,\n",
    "                                criterion=torch.nn.BCEWithLogitsLoss(),\n",
    "                                inputs=train_x, targets=train_y)\n",
    "        if pp == 0:\n",
    "            output = utils.gradtensor_to_tensor(temp_net, include_bn=True)\n",
    "            sub_hess = torch.zeros(output.nelement(), output.nelement())\n",
    "            sub_hess[:, pp] = output\n",
    "\n",
    "\n",
    "        sub_hess[:, pp] = utils.gradtensor_to_tensor(temp_net, include_bn=True).cpu()\n",
    "    \n",
    "    ## extract the indices of the hessian we care about ##\n",
    "    keepers = np.array(np.where(perm < n_keep))[0]\n",
    "    hessians[tt, :, :] = sub_hess[np.ix_(keepers, keepers)]\n",
    "    \n",
    "    ## now compute the losses for the subnetwork ##\n",
    "    outputs = temp_net(train_x)\n",
    "    losses[tt] = loss_func(outputs, train_y)\n",
    "    \n",
    "    outputs = temp_net(test_x)\n",
    "    test_losses[tt] = loss_func(outputs, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimus = optimus.cpu()\n",
    "optimus.train_net(print_loss=True, lr=0.01, iters=2000,\n",
    "                 loss_func=torch.nn.BCEWithLogitsLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = losses.argsort()\n",
    "losses = losses[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses[idx].detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hessians = hessians[idx, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_vals = torch.zeros(n_trial, n_keep)\n",
    "for tt in range(n_trial):\n",
    "    e_val, _ = np.linalg.eig(hessians[tt, :, :].cpu())\n",
    "    idx = np.abs(e_val).argsort()[::-1]   \n",
    "    e_val = torch.FloatTensor(e_val[idx].real)\n",
    "    e_vals[tt, :] = e_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_plt = torch.zeros_like(e_vals)\n",
    "for tt in range(n_trial):\n",
    "    x_plt[tt, :] = tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tt in range(n_trial):\n",
    "    plt.plot(x_plt[tt, :], e_vals[tt, :],\n",
    "            marker='.', alpha=0.5, linestyle='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_eval = torch.mean(e_vals, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_eval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10,8))\n",
    "for tt in range(n_trial):\n",
    "    ax1.plot(x_plt[tt, :], e_vals[tt, :],\n",
    "            marker=\".\", alpha=0.5, linestyle='None')\n",
    "ax1.set_ylabel(\"Eigenvalues\")\n",
    "\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(x_plt[:, 0], losses.detach(),\n",
    "        linewidth=2.)\n",
    "ax2.set_ylabel(\"BCE Loss\")\n",
    "ax1.set_xlabel(\"Index\")\n",
    "plt.title(\"Loss and Spectral Densities of Randomly Initialized Subnetworks\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = optimus(train_x.cpu())\n",
    "outputs = torch.zeros_like(outputs)\n",
    "ll = loss_func(outputs, train_y.cpu())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
