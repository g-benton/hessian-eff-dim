{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "from torch import nn\n",
    "\n",
    "import hess\n",
    "import hess.net_utils as net_utils\n",
    "import hess.utils as utils\n",
    "from hess.nets import MaskedNetLinear, SubNetLinear\n",
    "# from hess.nets import MaskedLayerLinear, SubLayerLinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twospirals(n_points, noise=.5, random_state=920):\n",
    "    \"\"\"\n",
    "     Returns the two spirals dataset.\n",
    "    \"\"\"\n",
    "    n = np.sqrt(np.random.rand(n_points,1)) * 600 * (2*np.pi)/360\n",
    "    d1x = -1.5*np.cos(n)*n + np.random.randn(n_points,1) * noise\n",
    "    d1y =  1.5*np.sin(n)*n + np.random.randn(n_points,1) * noise\n",
    "    return (np.vstack((np.hstack((d1x,d1y)),np.hstack((-d1x,-d1y)))),\n",
    "            np.hstack((np.zeros(n_points),np.ones(n_points))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Setting prune rate of network to 0.5\n",
      "==> Setting prune rate of sequential.0 to 0.5\n",
      "==> Setting prune rate of sequential.2 to 0.5\n",
      "==> Setting prune rate of sequential.4 to 0.5\n",
      "==> Setting prune rate of sequential.6 to 0.5\n",
      "==> Setting prune rate of sequential.8 to 0.5\n",
      "==> Setting prune rate of sequential.10 to 0.5\n",
      "==> Setting prune rate of sequential.12 to 0.5\n",
      "=> Freezing model weights\n",
      "==> No gradient to sequential.0.weight\n",
      "==> No gradient to sequential.0.bias\n",
      "==> No gradient to sequential.2.weight\n",
      "==> No gradient to sequential.2.bias\n",
      "==> No gradient to sequential.4.weight\n",
      "==> No gradient to sequential.4.bias\n",
      "==> No gradient to sequential.6.weight\n",
      "==> No gradient to sequential.6.bias\n",
      "==> No gradient to sequential.8.weight\n",
      "==> No gradient to sequential.8.bias\n",
      "==> No gradient to sequential.10.weight\n",
      "==> No gradient to sequential.10.bias\n",
      "==> No gradient to sequential.12.weight\n",
      "==> No gradient to sequential.12.bias\n",
      "==> Applied Weights\n",
      "==> Applied Mask\n",
      "tensor([1., 1., 1.,  ..., 1., 0., 1.], grad_fn=<ViewBackward>)\n"
     ]
    }
   ],
   "source": [
    "X, Y = twospirals(500, noise=1.3)\n",
    "train_x = torch.FloatTensor(X)\n",
    "train_y = torch.FloatTensor(Y).unsqueeze(-1)\n",
    "\n",
    "###################################\n",
    "## Set up nets and match weights ##\n",
    "###################################\n",
    "\n",
    "n_hidden = 5\n",
    "width = 15\n",
    "\n",
    "subnet_model = SubNetLinear(in_dim=2, out_dim=1, n_layers=n_hidden, k=width)\n",
    "masked_model = MaskedNetLinear(in_dim=2, out_dim=1, n_layers=n_hidden, k=width)\n",
    "\n",
    "hess.net_utils.set_model_prune_rate(subnet_model, 0.5)\n",
    "hess.net_utils.freeze_model_weights(subnet_model)\n",
    "\n",
    "weights = net_utils.get_weights_from_subnet(subnet_model)\n",
    "\n",
    "net_utils.apply_weights(masked_model, weights)\n",
    "mask = net_utils.get_mask_from_subnet(subnet_model)\n",
    "net_utils.apply_mask(masked_model, mask)\n",
    "mask = utils.flatten(mask)\n",
    "print(mask)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    torch.cuda.set_device(3)\n",
    "    train_x, train_y = train_x.cuda(), train_y.cuda()\n",
    "    subnet_model = subnet_model.cuda()\n",
    "    masked_model = masked_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1261\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in masked_model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6934, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "==> Applied Mask\n",
      "mask shape =  1170\n",
      "padded rhs shape =  torch.Size([1261, 1])\n",
      "mask shape =  torch.Size([1170])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [1170] at index 0does not match the shape of the indexed tensor [1261, 1] at index 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7d7b9e5338c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m         eigs = utils.get_hessian_eigs(loss_func, masked_model, mask=mask,\n\u001b[1;32m     27\u001b[0m                                       \u001b[0mn_eigs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_eigs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                                       train_y=train_y)\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0meigs_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meigs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/hess_truck/hess/utils.py\u001b[0m in \u001b[0;36mget_hessian_eigs\u001b[0;34m(loss, model, mask, use_cuda, n_eigs, train_x, train_y, loader, evals)\u001b[0m\n\u001b[1;32m    207\u001b[0m         qmat, tmat = lanczos_tridiag(hvp, n_eigs, dtype=dtype,\n\u001b[1;32m    208\u001b[0m                                   device=device, matrix_shape=(numpars,\n\u001b[0;32m--> 209\u001b[0;31m                                   numpars))\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0meigs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_evals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlanczos_tridiag_to_diag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/gpytorch/gpytorch/utils/lanczos.py\u001b[0m in \u001b[0;36mlanczos_tridiag\u001b[0;34m(matmul_closure, max_iter, dtype, device, matrix_shape, batch_shape, init_vecs, num_init_vecs, tol)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;31m# Initial alpha value: alpha_0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mr_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatmul_closure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_0_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0malpha_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_0_vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim_dimension\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/research/hess_truck/hess/utils.py\u001b[0m in \u001b[0;36mhvp\u001b[0;34m(rhs)\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"padded rhs shape = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_rhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mask shape = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0mpadded_rhs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrhs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m             \u001b[0mpadded_rhs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munflatten_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_rhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             eval_hess_vec_prod(padded_rhs, net=model,\n",
      "\u001b[0;31mIndexError\u001b[0m: The shape of the mask [1170] at index 0does not match the shape of the indexed tensor [1261, 1] at index 0"
     ]
    }
   ],
   "source": [
    "######################\n",
    "## Train the Subnet ##\n",
    "######################\n",
    "\n",
    "optimizer = torch.optim.Adam(subnet_model.parameters(), lr=0.01)\n",
    "loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "eigs_every = 10\n",
    "n_eigs = 100\n",
    "eigs_out = []\n",
    "\n",
    "for step in range(1000):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = subnet_model(train_x)\n",
    "\n",
    "    loss=loss_func(outputs,train_y)\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % eigs_every == 0:\n",
    "        mask = net_utils.get_mask_from_subnet(subnet_model)\n",
    "        net_utils.apply_mask(masked_model, mask)\n",
    "        mask = utils.flatten(mask)\n",
    "        print(\"mask shape = \", mask.numel())\n",
    "\n",
    "        eigs = utils.get_hessian_eigs(loss_func, masked_model, mask=mask,\n",
    "                                      n_eigs=n_eigs, train_x=train_x,\n",
    "                                      train_y=train_y)\n",
    "\n",
    "        eigs_out.append(eigs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = \"./saved-subnet-hessian/\"\n",
    "fname = \"subnet_eigs.pkl\"\n",
    "\n",
    "with open(fpath + fname, 'wb') as f:\n",
    "    pickle.dump(eigs_out, f)\n",
    "\n",
    "fname = \"subnet_model.pt\"\n",
    "torch.save(subnet_model.state_dict(), fpath + fname)\n",
    "\n",
    "fname = \"masked_model.pt\"\n",
    "torch.save(masked_model.state_dict(), fpath + fname)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
