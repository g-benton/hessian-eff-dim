{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import hess\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from hess.nets import MaskedNetLinear, SubNetLinear\n",
    "\n",
    "import hess.net_utils as net_utils\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x122f30750>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.random.manual_seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 5\n",
    "width = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SubNetLinear(2, 1, n_layers=n_hidden, k=width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Setting prune rate of network to 0.6\n",
      "==> Setting prune rate of sequential.0 to 0.6\n",
      "==> Setting prune rate of sequential.2 to 0.6\n",
      "==> Setting prune rate of sequential.4 to 0.6\n",
      "==> Setting prune rate of sequential.6 to 0.6\n",
      "==> Setting prune rate of sequential.8 to 0.6\n",
      "==> Setting prune rate of sequential.10 to 0.6\n",
      "==> Setting prune rate of sequential.12 to 0.6\n"
     ]
    }
   ],
   "source": [
    "hess.net_utils.set_model_prune_rate(model, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Freezing model weights\n",
      "==> No gradient to sequential.0.weight\n",
      "==> No gradient to sequential.0.bias\n",
      "==> No gradient to sequential.2.weight\n",
      "==> No gradient to sequential.2.bias\n",
      "==> No gradient to sequential.4.weight\n",
      "==> No gradient to sequential.4.bias\n",
      "==> No gradient to sequential.6.weight\n",
      "==> No gradient to sequential.6.bias\n",
      "==> No gradient to sequential.8.weight\n",
      "==> No gradient to sequential.8.bias\n",
      "==> No gradient to sequential.10.weight\n",
      "==> No gradient to sequential.10.bias\n",
      "==> No gradient to sequential.12.weight\n",
      "==> No gradient to sequential.12.bias\n"
     ]
    }
   ],
   "source": [
    "hess.net_utils.freeze_model_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twospirals(n_points, noise=.5, random_state=920):\n",
    "    \"\"\"\n",
    "     Returns the two spirals dataset.\n",
    "    \"\"\"\n",
    "    n = np.sqrt(np.random.rand(n_points,1)) * 600 * (2*np.pi)/360\n",
    "    d1x = -1.5*np.cos(n)*n + np.random.randn(n_points,1) * noise\n",
    "    d1y =  1.5*np.sin(n)*n + np.random.randn(n_points,1) * noise\n",
    "    return (np.vstack((np.hstack((d1x,d1y)),np.hstack((-d1x,-d1y)))),\n",
    "            np.hstack((np.zeros(n_points),np.ones(n_points))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = twospirals(500, noise=1.3)\n",
    "train_x = torch.FloatTensor(X)\n",
    "train_y = torch.FloatTensor(Y).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6931, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(0.6866, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(0.6599, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(0.6137, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(0.6405, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(0.6087, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(0.6021, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(0.6104, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(0.6109, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(0.6024, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(0.5925, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(0.5950, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(0.5983, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(0.5906, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(0.5882, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(0.5899, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(0.5902, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(0.5879, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(0.5851, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(0.5843, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(0.5859, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(0.5836, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n",
      "tensor(0.5814, grad_fn=<BinaryCrossEntropyWithLogitsBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b16d4c75b288>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//miniconda3/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                     \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_func = torch.nn.BCEWithLogitsLoss()\n",
    "losses = []\n",
    "\n",
    "for step in range(2000):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(train_x)\n",
    "\n",
    "    loss=loss_func(outputs,train_y)\n",
    "    print(loss)\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses = [l() for l in losses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 5))\n",
    "plt.plot(losses[:500])\n",
    "plt.ylim(0., 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer = 0.3\n",
    "h = 0.1\n",
    "x_min, x_max = train_x[:, 0].min() - buffer, train_x[:, 0].max() + buffer\n",
    "y_min, y_max = train_x[:, 1].min() - buffer, train_x[:, 1].max() + buffer\n",
    "\n",
    "xx,yy=np.meshgrid(np.arange(x_min.cpu(), x_max.cpu(), h), \n",
    "                  np.arange(y_min.cpu(), y_max.cpu(), h))\n",
    "in_grid = torch.FloatTensor([xx.ravel(), yy.ravel()]).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.sigmoid(model(in_grid).squeeze().cpu()).reshape(xx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.contourf(xx, yy, pred.detach(), alpha=0.5)\n",
    "# plt.title(\"Temp Scaled\", fontsize=24)\n",
    "plt.title(\"Classifier\", fontsize=24)\n",
    "plt.colorbar()\n",
    "plt.scatter(train_x[:, 0].cpu(), train_x[:, 1].cpu(), c=train_y[:, 0].cpu(), cmap=plt.cm.binary)\n",
    "plt.savefig(\"./two-spiral-classifier.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.sigmoid(model(in_grid).squeeze().cpu()).reshape(xx.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
