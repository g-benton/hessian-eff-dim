{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_palette('colorblind')\n",
    "%matplotlib inline\n",
    "np.random.seed(88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random weakly informative features copied from\n",
    "# https://github.com/ORIE4741/demos/blob/master/double-descent.ipynb\n",
    "def build_random_features(n=100, d=100, num_informative_features = 20):\n",
    "    y = np.random.randn(n)\n",
    "    X = np.random.randn(n, min(d, num_informative_features)) + y.reshape(-1,1)\n",
    "\n",
    "    if d > num_informative_features:\n",
    "        X = np.hstack((X, np.random.randn(n,d - num_informative_features)))\n",
    "    \n",
    "    return X,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eff_dim(x, s=0.1):\n",
    "    return np.sum(x / (x + s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_partial_error(d, n=200, l=0.001):\n",
    "    xtrain, ytrain = build_random_features(n=n, d = d, num_informative_features=1000)\n",
    "    xtest, ytest = build_random_features(n=n, d = d, num_informative_features=1000)\n",
    "\n",
    "    w = np.linalg.lstsq(xtrain, ytrain, rcond=None)[0]\n",
    "    \n",
    "    alpha = np.linalg.lstsq(xtrain @ xtrain.T +  n * l * np.eye(xtrain.shape[0]), ytrain)[0]\n",
    "    train_norm = alpha.T @ xtrain @ (xtrain.T @ alpha)\n",
    "    \n",
    "    test_error = np.linalg.norm(xtest @ w - ytest) / np.linalg.norm(ytest)\n",
    "    train_error = np.linalg.norm(xtrain @ w - ytrain) / np.linalg.norm(ytrain)\n",
    "    \n",
    "    svs = np.linalg.svd(xtrain, compute_uv=False)\n",
    "    #eigs = np.linalg.eigvals(xtrain @ xtrain.T)\n",
    "    effective_dimensions = min(n, d) - eff_dim(svs**2, s=(l*n))\n",
    "    \n",
    "    return test_error, train_error, train_norm**0.5, effective_dimensions, svs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width_sequence = range(5, 400, 2)\n",
    "errors = [compute_partial_error(d) for d in width_sequence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_fs = 28\n",
    "ax_fs = 26\n",
    "leg_fs = 26\n",
    "tick_size = 16\n",
    "lw = 2\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "colors = sns.color_palette(\"bright\")\n",
    "fig, ax = plt.subplots(1, 1, figsize=(14,6))\n",
    "ax.plot(width_sequence, [e[0] for e in errors], label='Test Error', color=colors[0],\n",
    "       linewidth=lw)\n",
    "ax.plot(width_sequence, [e[1] for e in errors], label='Train Error', color=colors[1],\n",
    "       linewidth=lw)\n",
    "ax.tick_params(axis='both', labelsize=tick_size)\n",
    "#ax.plot(width_sequence, [e[2] for e in errors], label='Hilbert Space Norm')\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "ax2.plot(width_sequence, [e[3] for e in errors], label = 'Effective Dimensionality', color=colors[2],\n",
    "        linewidth=lw)\n",
    "ax2.tick_params(axis='y', labelsize=tick_size)\n",
    "\n",
    "ymin = 0\n",
    "ymax = 1.1 * max([e[0] for e in errors])\n",
    "ax.set_ylim(ymin, ymax)\n",
    "ax.axvspan(0, 175, alpha=0.1, color='red')\n",
    "ax.axvspan(175, 225, alpha=0.1, color='yellow')\n",
    "ax.axvspan(225, 400, alpha=0.1, color='green')\n",
    "\n",
    "ax.fill_between([175, 225], ymin, ymax, facecolor=\"None\", edgecolor='k', hatch=\"/\",\n",
    "                alpha=0.3)\n",
    "ax.fill_between([225, 400], ymin, ymax, facecolor=\"None\", edgecolor='k', hatch=\"X\",\n",
    "                alpha=0.3)\n",
    "\n",
    "# ask matplotlib for the plotted objects and their labels\n",
    "lines, labels = ax.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines + lines2, labels + labels2, loc=0, fontsize=leg_fs)\n",
    "#ax.legend()\n",
    "\n",
    "ax.set_ylabel('Risk', fontsize=ax_fs)\n",
    "ax.set_xlabel('Number of Features', fontsize=ax_fs)\n",
    "ax2.set_ylabel('Effective Dimensionality', fontsize=ax_fs)\n",
    "#plt.ylim((0, 0.3))\n",
    "plt.xlim((0,400))\n",
    "plt.tight_layout()\n",
    "plt.savefig('random_featues_double_descent.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(14,6))\n",
    "\n",
    "plt.scatter([e[3] for e in errors], [e[0] for e in errors])\n",
    "plt.xlabel('Effective Dimensionality', fontsize=16)\n",
    "plt.ylabel('Test Error', fontsize=16)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.savefig('random_features_generalization.pdf', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = range(10, 1200, 20)\n",
    "data_points = range(10, 1200, 20)\n",
    "\n",
    "risk_tensor = np.zeros((4, len(list(dimensions)), len(list(dimensions))))\n",
    "for i, d in enumerate(dimensions):\n",
    "    for j, n in enumerate(data_points):\n",
    "        output = compute_partial_error(d=d, n=n)\n",
    "        risk_tensor[:, i, j] = output[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize = (16, 6))\n",
    "\n",
    "im = ax[0].contourf(dimensions, data_points, np.log(risk_tensor[0]))\n",
    "ax[0].set_ylabel('Number of Random Features')\n",
    "ax[0].set_xlabel('Number of Data Points')\n",
    "ax[0].set_title('Test Error')\n",
    "fig.colorbar(im, label='Log(Test Error)', ax=ax[0])\n",
    "\n",
    "im = ax[1].contourf(dimensions, data_points, np.log(risk_tensor[1]))\n",
    "ax[1].set_title('Train Error')\n",
    "ax[1].set_ylabel('Number of Random Features')\n",
    "ax[1].set_xlabel('Number of Data Points')\n",
    "fig.colorbar(im, label='Train Error', ax=ax[1])\n",
    "\n",
    "im = ax[2].contourf(dimensions, data_points, np.log(risk_tensor[2]))\n",
    "ax[2].set_title('Hilbert Space Norm')\n",
    "ax[2].set_ylabel('Number of Random Features')\n",
    "ax[2].set_xlabel('Number of Data Points')\n",
    "fig.colorbar(im, label='Log(Hilbert Space Norm)',ax=ax[2])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.contourf(dimensions, data_points, risk_tensor[1])\n",
    "plt.colorbar(label='Train Error')\n",
    "plt.xlabel('Number of Data Points')\n",
    "plt.ylabel('Number of Random Features')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.log(risk_tensor[2]), extent=[10, 1000, 1000, 10])\n",
    "plt.colorbar()\n",
    "plt.xlabel('Number of Data Points')\n",
    "plt.ylabel('Number of Random Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.contourf(dimensions, data_points, np.log(risk_tensor[2]))\n",
    "plt.xlabel('Number of Random Features')\n",
    "plt.ylabel('Number of Data Points')\n",
    "plt.colorbar(label='Log(Hilbert Space Norm)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svds = [np.linalg.svd(build_random_features(n=200, d = d, \n",
    "                                            num_informative_features=1000)[0])[1] for d in range(10, 1000, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['blue', 'red']\n",
    "for s, d in zip(svds, range(10, 1000, 5)):\n",
    "    plt.plot(2*np.log(s+3), color = colors[d < 150 or d > 250])\n",
    "plt.xlabel('Order')\n",
    "plt.ylabel('Log Eigenvalue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
